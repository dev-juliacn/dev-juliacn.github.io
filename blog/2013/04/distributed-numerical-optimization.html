<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
<meta http-equiv="x-ua-compatible" content="ie=edge">
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title>Distributed Numerical Optimization</title>
<meta name="author" content="Jeff Bezanson, Stefan Karpinski, Viral Shah, Alan Edelman, et al." />
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link href="https://fonts.googleapis.com/css?family=Roboto:400,400i,500,500i,700,700i" rel="stylesheet">
<link rel="stylesheet" href="/v2/css/bootstrap.min.css" />
<link rel="stylesheet" href="/v2/css/app.css" />
<link rel="stylesheet" href="/v2/css/fonts.css" />
<link rel="stylesheet" href="/v2/css/highlight/github.css" />
</head>

<body>

   

<!-- main menu -->
<div class="container py-3 py-lg-0">
  <nav class="navbar navbar-expand-lg navbar-light bg-light" id="main-menu">

    <a class="navbar-brand" href="/" id="logo">
      <img src="/v2/img/logo.png" height="55" width="118" />
    </a>

    <button class="navbar-toggler ml-auto hidden-sm-up float-xs-left" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <!-- li class="nav-item  flex-md-fill text-md-center">
          <a class="nav-link" href="/">Home</a>
        </li -->
        <li class="nav-item  flex-md-fill text-md-center">
          <a class="nav-link" href="/downloads">下载</a>
        </li>
        <li class="nav-item flex-md-fill text-md-center">
          <a class="nav-link" href="http://docs.juliacn.com/">文档</a>
        </li>
        <li class="nav-item  active  flex-md-fill text-md-center">
          <a class="nav-link" href="/blog/">Blog</a>
        </li>
        <li class="nav-item  flex-md-fill text-md-center">
          <a class="nav-link" href="/meetups">活动</a>
        </li>
      </ul>
    </div>

  </nav>
</div>
<!-- end main menu -->


   <br /><br />

  <div class="container">
    <br /><br />

<div class="container">

  <div class="row">
    <div class="col-12 col-lg-8 offset-lg-2">
      <h1></h1>

<div id="blogpost">
  <h1>Distributed Numerical Optimization</h1>

  <p class="metadata">
    <span class="timestamp">05 Apr 2013</span>
    
    &nbsp;|&nbsp;
    <span class="author">
      
        <a href="http://www.mit.edu/~mlubin/">Miles Lubin</a>
      
    </span>
    
  </p>

  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<p>This post walks through the parallel computing functionality of Julia
to implement an asynchronous parallel version of the classical
<em>cutting-plane</em> algorithm for convex (nonsmooth) optimization,
demonstrating the complete workflow including running on both Amazon
EC2 and a large multicore server. I will quickly review the
cutting-plane algorithm and will be focusing primarily on parallel
computation patterns, so don’t worry if you’re not familiar with the
optimization side of things.</p>

<h3 id="cutting-plane-algorithm">Cutting-plane algorithm</h3>

<p>The cutting-plane algorithm is a method for solving the optimization problem</p>

<script type="math/tex; mode=display">\min_{x \in \mathbb R^d} \sum_{i=1}^n f_i(x)</script>

<p>where the functions \( f_i \) are convex but not necessarily differentiable.
The absolute value function \( |x| \) and the 1-norm \( ||x|| _ 1 \) are
typical examples. Important applications also arise from <a href="http://en.wikipedia.org/wiki/Lagrangian_relaxation">Lagrangian
relaxation</a>. The idea of the algorithm is to approximate the functions \(
f_i \) with piecewise linear models \( m_i \) which are built up from
information obtained by evaluating \( f_i \) at different points. We
iteratively minimize over the models to generate candidate solution points.</p>

<p>We can state the algorithm as</p>

<ol>
  <li>Choose starting point \( x \).</li>
  <li>For \(i = 1,\ldots,n\), evaluate \(
f_i(x) \) and update corresponding model \( m_i \).</li>
  <li>Let the next
candidate \( x \) be the minimizer of \( \sum_{i=1}^n m_i(x) \).</li>
  <li>If not converged, goto step 2.</li>
</ol>

<p>If it is costly to evaluate \( f_i(x) \), then the algorithm is naturally
parallelizable at step 2. The minimization in step 3 can be computed by solving
a linear optimization problem, which is usually very fast. (Let me point out
here that Julia has interfaces to linear programming and other
optimization solvers under <a href="http://juliaopt.org/">JuliaOpt</a>.)</p>

<p>Abstracting the math, we can write the algorithm using the following Julia code.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># functions initialize, isconverged, solvesubproblem, and process implemented elsewhere
state, subproblems = initialize()
while !isconverged(state)
    results = map(solvesubproblem,subproblems)
    state, subproblems = process(state, results)
end
</code></pre></div></div>

<p>The function <code class="highlighter-rouge">solvesubproblem</code> corresponds to evaluating \( f_i(x) \) for a
given \( i \) and \( x \) (the elements of <code class="highlighter-rouge">subproblems</code> could be tuples
<code class="highlighter-rouge">(i,x)</code>). The function <code class="highlighter-rouge">process</code> corresponds to minimizing the model in step
3, and it produces a new state and a new set of subproblems to solve.</p>

<p>Note that the algorithm looks much like a map-reduce that would be easy to
parallelize using many existing frameworks. Indeed, in Julia we can simply
replace <code class="highlighter-rouge">map</code> with <code class="highlighter-rouge">pmap</code> (parallel map). Let’s consider a twist that makes
the parallelism not so straightforward.</p>

<h3 id="asynchronous-variant">Asynchronous variant</h3>

<p>Variability in the time taken by the <code class="highlighter-rouge">solvesubproblem</code> function can lead to
load imbalance and limit parallel efficiency as workers sit idle waiting for new
tasks. Such variability arises naturally if <code class="highlighter-rouge">solvesubproblem</code> itself requires
solving a optimization problem, or if the workers and network are shared, as is
often the case with cloud computing.</p>

<p>We can consider a new variant of the cutting-plane algorithm to address this
issue. The key point is</p>

<ul>
  <li>When proportion \(0 &lt; \alpha \le 1 \) of subproblems for a given candidate
have been solved, generate a new candidate and corresponding set of
subproblems by using whatever information is presently available.</li>
</ul>

<p>In other words, we generate new tasks to feed to workers without needing to wait
for all current tasks to complete, making the algorithm asynchronous. The
algorithm remains convergent, although the total number of iterations may
increase. For more details, see this <a href="http://dx.doi.org/10.1023/A:1021858008222">paper</a> by Jeff Linderoth and
Stephen Wright.</p>

<p>By introducing asynchronicity we can no longer use a nice black-box <code class="highlighter-rouge">pmap</code>
function and have to dig deeper into the parallel implementation. Fortunately,
this is easy to do in Julia.</p>

<h3 id="parallel-implementation-in-julia">Parallel implementation in Julia</h3>

<p>Julia implements distributed-memory parallelism based on one-sided message
passing, where process push work onto others (via <code class="highlighter-rouge">remotecall</code>) and the
results are retrieved (via <code class="highlighter-rouge">fetch</code>) by the process which requires them. Macros
such as <code class="highlighter-rouge">@spawn</code> and <code class="highlighter-rouge">@parallel</code> provide pretty syntax around this low-level
functionality.  This model of parallelism is very different from the typical
SIMD style of MPI. Both approaches are useful in different contexts, and I
expect an MPI wrapper for Julia will appear in the future (see also <a href="https://github.com/lcw/julia-mpi">here</a>).</p>

<p>Reading the <a href="http://docs.julialang.org/en/release-0.1/manual/parallel-computing/">manual</a>
on parallel computing is highly recommended, and I won’t try to reproduce it in
this post. Instead, we’ll dig into and extend one of the examples it presents.</p>

<p>The implementation of <code class="highlighter-rouge">pmap</code> in Julia is</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>function pmap(f, lst)
    np = nprocs()  # determine the number of processors available
    n = length(lst)
    results = cell(n)
    i = 1
    # function to produce the next work item from the queue.
    # in this case it's just an index.
    next_idx() = (idx=i; i+=1; idx)
    @sync begin
        for p=1:np
            if p != myid() || np == 1
                @spawnlocal begin
                    while true
                        idx = next_idx()
                        if idx &gt; n
                            break
                        end
                        results[idx] = remotecall_fetch(p, f, lst[idx])
                    end
                end
            end
        end
    end
    results
end
</code></pre></div></div>

<p>On first sight, this code is not particularly intuitive. The <code class="highlighter-rouge">@spawnlocal</code>
macro creates a <em><a href="http://docs.julialang.org/en/latest/manual/control-flow/#man-tasks">task</a></em>
on the <em>master process</em> (e.g. process 1). Each task feeds work to a
corresponding worker; the call <code class="highlighter-rouge">remotecall_fetch(p, f, lst[idx])</code> function
calls <code class="highlighter-rouge">f</code> on process <code class="highlighter-rouge">p</code> and returns the result when finished. Tasks are
uninterruptable and only surrender control at specific points such as
<code class="highlighter-rouge">remotecall_fetch</code>. Tasks cannot directly modify variables from the enclosing
scope, but the same effect can be achieved by using the <code class="highlighter-rouge">next_idx</code> function to
access and mutate <code class="highlighter-rouge">i</code>. <em>The task idiom functions in place of using a loop to
poll for results from each worker process.</em></p>

<p>Implementing our asynchronous algorithm is not much more than a modification of
the above code:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># given constants n and 0 &lt; alpha &lt;= 1
# functions initialize and solvesubproblem defined elsewhere
np = nprocs()
state, subproblems = initialize()
converged = false
isconverged() = converged
function updatemodel(mysubproblem, result)
    # store result
    ...
    # decide whether to generate new subproblems
    state.numback[mysubproblem.parent] += 1
    if state.numback[mysubproblem.parent] &gt;= alpha*n &amp;&amp; !state.didtrigger[mysubproblem.parent]
        state.didtrigger[mysubproblem.parent] = true
        # generate newsubproblems by solving linear optimization problem
        ...
        if ... # convergence test
            converged = true
        else
            append!(subproblems, newsubproblems)
            push!(state.didtrigger, false)
            push!(state.numback, 0)
            # ensure that for s in newsubproblems, s.parent == length(state.numback)
        end
    end
end

@sync begin
    for p=1:np
        if p != myid() || np == 1
            @spawnlocal begin
                while !isconverged()
                    if length(subproblems) == 0
                        # no more subproblems but haven't converged yet
                        yield()
                        continue
                    end
                    mysubproblem = shift!(subproblems) # pop subproblem from queue
                    result = remotecall_fetch(p, solvesubproblem, mysubproblem)
                    updatemodel(mysubproblem, result)
                end
            end
        end
    end
end
</code></pre></div></div>

<p>where <code class="highlighter-rouge">state</code> is an instance of a type defined as</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>type State
    didtrigger::Vector{Bool}
    numback::Vector{Int}
    ...
end
</code></pre></div></div>

<p>There is little difference in the structure of the code inside the <code class="highlighter-rouge">@sync</code>
blocks, and the asynchronous logic is encapsulated in the local <code class="highlighter-rouge">updatemodel</code>
function which conditionally generates new subproblems. A strength of Julia is
that functions like <code class="highlighter-rouge">pmap</code> are implemented in Julia itself, so that it is
particularly straightforward to make modifications like this.</p>

<h3 id="running-it">Running it</h3>

<p>Now for the fun part. The complete cutting-plane algorithm (along with
additional variants) is implemented in <a href="https://github.com/mlubin/JuliaBenders">JuliaBenders</a>. The code is
specialized for <a href="http://en.wikipedia.org/wiki/Stochastic_programming">stochastic
programming</a> where the cutting-plane algorithm is known as the <a href="http://www.springerreference.com/docs/html/chapterdbid/72429.html">L-shaped
method</a> or Benders decomposition and is used to decompose the solution of
large linear optimization problems. Here, <code class="highlighter-rouge">solvesubproblem</code> entails solving a
relatively small linear optimization problem. Test instances are taken from the
previously mentioned <a href="http://dx.doi.org/10.1023/A:1021858008222">paper</a>.</p>

<p>We’ll first run on a large multicore server. The
<code class="highlighter-rouge">runals.jl</code> (asynchronous L-shaped) file contains the algorithm we’ll use. Its
usage is</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>julia runals.jl [data source] [num subproblems] [async param] [block size]
</code></pre></div></div>

<p>where <code class="highlighter-rouge">[num subproblems]</code> is the \(n\) as above and <code class="highlighter-rouge">[async param]</code> is
the proportion \(\alpha\). By setting \(\alpha = 1\) we obtain the
synchronous algorithm. For the asynchronous version we will take \(\alpha =
0.6\). The <code class="highlighter-rouge">[block size]</code> parameter controls how many subproblems are sent to
a worker at once (in the previous code, this value was always 1). We will use
4000 subproblems in our experiments.</p>

<p>To run multiple Julia processes on a shared-memory machine, we pass the <code class="highlighter-rouge">-p N</code>
option to the <code class="highlighter-rouge">julia</code> executable, which will start up <code class="highlighter-rouge">N</code> system processes.
To execute the asynchronous version with 10 workers, we run</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>julia -p 12 runals.jl Data/storm 4000 0.6 30
</code></pre></div></div>

<p>Note that we start 12 processes. These are the 10 workers, the master (which
distributes tasks), and another process to perform the master’s computations (an
additional refinement which was not described above). Results from various runs
are presented in the table below.</p>

<table style="text-align:right;margin-left:auto;margin-right:auto" cellspacing="5">
<tr style="text-align:center">
	<td> </td>
	<td colspan="2" style="border-bottom-style:solid;border-bottom-width:2px">Synchronous</td>
	<td colspan="2" style="border-bottom-style:solid;border-bottom-width:2px">Asynchronous</td>
</tr>
<tr style="text-align:center">
	<td style="border-bottom-style:solid;border-bottom-width:2px">No. Workers</td>
	<td style="border-bottom-style:solid;border-bottom-width:2px">Speed</td>
	<td style="border-bottom-style:solid;border-bottom-width:2px">Efficiency
	<td style="border-bottom-style:solid;border-bottom-width:2px">Speed</td>
	<td style="border-bottom-style:solid;border-bottom-width:2px">Efficiency
</td></td></tr>
<tr>
	<td style="text-align:center">10</td>
	<td>154</td>
	<td>Baseline</td>
	<td>166</td>
	<td>Baseline</td>
</tr>
<tr>
	<td style="text-align:center">20</td>
	<td>309</td>
	<td>100.3%</td>
	<td>348</td>
	<td>105%</td>
</tr>
<tr>
	<td style="text-align:center">40</td>
	<td>517</td>
	<td>84%</td>
	<td>654</td>
	<td>98%</td>
</tr>
<tr>
	<td style="text-align:center">60</td>
	<td>674</td>
	<td>73%</td>
	<td>918</td>
	<td>92%</td>
</tr>
</table>

<p class="caption" style="text-align:center"><b>Table:</b>
Results on a shared-memory 8x Xeon E7-8850 server. Workers correspond to
individual cores. Speed is the rate of subproblems solved per second. Efficiency
is calculated as the percent of ideal parallel speedup obtained. The superlinear
scaling observed with 20 workers is likely a system artifact.
</p>

<p>There are a few more hoops to jump through in order to run on EC2. First we must
build a system image (AMI) with Julia installed. Julia connects to workers over
ssh, so I found it useful to put my EC2 ssh key on the AMI and also set
<code class="highlighter-rouge">StrictHostKeyChecking no</code> in <code class="highlighter-rouge">/etc/ssh/ssh_config</code> to disable the
authenticity prompt when connecting to new workers. Someone will likely correct
me on if this is the right approach.</p>

<p>Assuming we have an AMI in place, we can fire up the instances. I used an
m3.xlarge instance for the master and m1.medium instances for the workers.
(Note: you can save a lot of money by using the spot market.)</p>

<p>To add remote workers on startup, Julia accepts a file with a list of host names
through the <code class="highlighter-rouge">--machinefile</code> option. We can generate this easily enough by
using the EC2 API Tools (Ubuntu package <code class="highlighter-rouge">ec2-api-tools</code>) with the command</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ec2-describe-instances | grep running | awk '{ print $5; }' &gt; mfile
</code></pre></div></div>

<p>On the master instance we can then run</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>julia --machinefile mfile runatr.jl Data/storm 4000 0.6 30
</code></pre></div></div>

<p>Results from various runs are presented in the table below.</p>

<table style="text-align:right;margin-left:auto;margin-right:auto" cellspacing="5">
<tr style="text-align:center">
	<td> </td>
	<td colspan="2" style="border-bottom-style:solid;border-bottom-width:2px">Synchronous</td>
	<td colspan="2" style="border-bottom-style:solid;border-bottom-width:2px">Asynchronous</td>
</tr>
<tr style="text-align:center">
	<td style="border-bottom-style:solid;border-bottom-width:2px">No. Workers</td>
	<td style="border-bottom-style:solid;border-bottom-width:2px">Speed</td>
	<td style="border-bottom-style:solid;border-bottom-width:2px">Efficiency
	<td style="border-bottom-style:solid;border-bottom-width:2px">Speed</td>
	<td style="border-bottom-style:solid;border-bottom-width:2px">Efficiency
</td></td></tr>
<tr>
	<td style="text-align:center">10</td>
	<td>149</td>
	<td>Baseline</td>
	<td>151</td>
	<td>Baseline</td>
</tr>
<tr>
	<td style="text-align:center">20</td>
	<td>289</td>
	<td>97%</td>
	<td>301</td>
	<td>99.7%</td>
</tr>
<tr>
	<td style="text-align:center">40</td>
	<td>532</td>
	<td>89%</td>
	<td>602</td>
	<td>99.5%</td>
</tr>
</table>

<p class="caption" style="text-align:center"><b>Table:</b>
Results on Amazon EC2. Workers correspond to individual m1.medium instances. The
master process is run on an m3.xlarge instance.
</p>

<p>On both architectures the asynchronous version solves subproblems at a higher
rate and has significantly better parallel efficiency. Scaling is better on EC2
than on the shared-memory server likely because the subproblem calculation is
memory bound, and so performance is better on the distributed-memory
architecture. Anyway, with Julia we can easily experiment on both.</p>

<h3 id="further-reading">Further reading</h3>

<p>A more detailed <a href="https://github.com/JuliaLang/julia-tutorial/blob/master/NumericalOptimization/tutorial.pdf?raw=true">tutorial</a>
was prepared for the Julia <a href="https://github.com/JuliaLang/julia-tutorial">IAP session</a> at MIT in January 2013.</p>

<p><a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br /><span xmlns:dct="http://purl.org/dc/terms/" property="dct:title">Distributed Numerical Optimization</span> by <span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName">Miles Lubin</span> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</p>


</div>



</div>
</div>
</div>

<br />


  </div>

  <footer class="container-fluid footer-copy">
  <div class="container">
    <div class="row">
      <div class="col-md-10 py-2">
        <p>
           ©2018 JuliaCN Julia 中文社区. All rights reserved.
        </p>
      </div>
    </div>
  </div>
</footer>

  <script src="/v2/js/jquery.min.js"></script>
<script src="/v2/js/bootstrap.min.js"></script>
<script src="/v2/js/platform.js"></script>
<script src="/v2/js/app.js"></script>
<script src="/v2/js/highlight.pack.js"></script>
<script async defer src="https://buttons.github.io/buttons.js"></script>
</body>

</html>
