<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
<meta http-equiv="x-ua-compatible" content="ie=edge">
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title>Generalizing AbstractArrays: opportunities and challenges</title>
<meta name="author" content="Jeff Bezanson, Stefan Karpinski, Viral Shah, Alan Edelman, et al." />
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link href="https://fonts.googleapis.com/css?family=Roboto:400,400i,500,500i,700,700i" rel="stylesheet">
<link rel="stylesheet" href="/v2/css/bootstrap.min.css" />
<link rel="stylesheet" href="/v2/css/app.css" />
<link rel="stylesheet" href="/v2/css/fonts.css" />
<link rel="stylesheet" href="/v2/css/highlight/github.css" />
</head>

<body>

   

<!-- main menu -->
<div class="container py-3 py-lg-0">
  <nav class="navbar navbar-expand-lg navbar-light bg-light" id="main-menu">

    <a class="navbar-brand" href="/" id="logo">
      <img src="/v2/img/logo.png" height="55" width="118" />
    </a>

    <button class="navbar-toggler ml-auto hidden-sm-up float-xs-left" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <!-- li class="nav-item  flex-md-fill text-md-center">
          <a class="nav-link" href="/">Home</a>
        </li -->
        <li class="nav-item  flex-md-fill text-md-center">
          <a class="nav-link" href="/downloads">下载</a>
        </li>
        <li class="nav-item flex-md-fill text-md-center">
          <a class="nav-link" href="http://docs.juliacn.com/">文档</a>
        </li>
        <li class="nav-item  active  flex-md-fill text-md-center">
          <a class="nav-link" href="/blog/">Blog</a>
        </li>
        <li class="nav-item  flex-md-fill text-md-center">
          <a class="nav-link" href="/meetups">活动</a>
        </li>
      </ul>
    </div>

  </nav>
</div>
<!-- end main menu -->


   <br /><br />

  <div class="container">
    <br /><br />

<div class="container">

  <div class="row">
    <div class="col-12 col-lg-8 offset-lg-2">
      <h1></h1>

<div id="blogpost">
  <h1>Generalizing AbstractArrays: opportunities and challenges</h1>

  <p class="metadata">
    <span class="timestamp">27 Mar 2016</span>
    
    &nbsp;|&nbsp;
    <span class="author"><a href="http://holylab.wustl.edu">Tim Holy</a></span>
    
  </p>

  <h1 id="introduction-generic-algorithms-with-abstractarrays">Introduction: generic algorithms with AbstractArrays</h1>

<p>Somewhat unusually, this blog post is future-looking: it mostly
focuses on things that don’t yet exist. Its purpose is to lay out the
background for community discussion about possible changes to the core
API for <code class="highlighter-rouge">AbstractArray</code>s, and serves as background reading and
reference material for a more focused “julep” (a julia enhancement
proposal).  Here, often I’ll use the shorthand “array” to mean
<code class="highlighter-rouge">AbstractArray</code>, and use <code class="highlighter-rouge">Array</code> if I explicitly mean julia’s concrete
<code class="highlighter-rouge">Array</code> type.</p>

<p>As the reader is likely aware, in julia it’s possible to write
algorithms for which one or more inputs are only assumed to be
<code class="highlighter-rouge">AbstractArray</code>s.  This is “generic” code, meaning it should work
(i.e., produce a correct result) on any specific concrete array type.
In an ideal world—which julia approaches rather well in many
cases—generality of code should not have a negative impact on its
performance: a generic implementation should be approximately as fast
as one restricted to specific array type(s).  This implies that
generic algorithms should be written using lower-level operations that
give good performance across a wide variety of array types.</p>

<p>Providing efficient low-level operations is a different kind of design
challenge than one experiences with programming languages that
“vectorize” everything.  When successful, it promotes much greater
reuse of code, because efficient, generic low-level parts allow you to
write a wide variety of efficient, generic higher-level functions.</p>

<p>Naturally, as the diversity of array types grows, the more careful we
have to be about our abstractions for these low-level operations.</p>

<h1 id="examples-of-arrays">Examples of arrays</h1>

<p>In discussing general operations on arrays, it’s useful to have a
diverse collection of concrete arrays in mind.</p>

<p>In core julia, some types we support fairly well are:</p>

<ul>
  <li>
    <p><code class="highlighter-rouge">Array</code>: the prototype for all arrays</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">Range</code>s: a good example of what I often consider a “computed”
array, where essentially none of the values are stored in
memory. Since there is no storage, these are immutable containers:
you can’t set values in individual slots.</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">BitArray</code>s: arrays that can only store 0 or 1 (<code class="highlighter-rouge">false</code> or <code class="highlighter-rouge">true</code>),
and for which the internal storage is packed so that each entry
requires only one bit.</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">SubArray</code>s: the problems this type introduced, and the resolution
we adopted, probably serves as the best model for the
generalizations considered here. Therefore, this case is discussed
in greater detail below.</p>
  </li>
</ul>

<p>Another important class of array types in Base are sparse arrays:
<code class="highlighter-rouge">SparseMatrixCSC</code> and <code class="highlighter-rouge">SparseVector</code>, as well as other sparse
representations like <code class="highlighter-rouge">Diagonal</code>, <code class="highlighter-rouge">Bidiagonal</code>, and <code class="highlighter-rouge">Tridiagonal</code>.
These are good examples of array types where access patterns deserve
careful thought. Notably, despite many commonalities in “strategy”
among the 5 or so sparse parametrizations we have, implementations of
core algorithms (e.g., matrix multiplication) are specialized for each
sparse-like type—in other words, these mimic the “high level
vectorized functions” strategy common to other languages. What we lack
is a “sparse iteration API” that lets you write the main algorithms of
sparse linear algebra efficiently in a generic way.  Our current model
is probably fine for <code class="highlighter-rouge">SparseLike*Dense</code> operations, but gets to be
harder to manage if you want to efficiently compute, e.g., <code class="highlighter-rouge">Bidiagonal*SparseMatrixCSC</code>: the number of possible combinations you have to
support grows rapidly with more sparse types, and thus represents a
powerful incentive for developing efficient, generic low-level
operations.</p>

<p>Outside of Base, there are some other mind-stretching examples of
arrays, including:</p>

<ul>
  <li>
    <p><code class="highlighter-rouge">DataFrames</code>: indexing arrays with symbols rather than
integers. Other related types include <code class="highlighter-rouge">NamedArrays</code>, <code class="highlighter-rouge">AxisArrays</code>.</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">Interpolations</code>: indexing arrays with non-integer floating-point
numbers</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">DistributedArrays</code>: another great example of a case in which you
need to think through access patterns carefully</p>
  </li>
</ul>

<h1 id="subarrays-a-case-study">SubArrays: a case study</h1>

<p>For arrays of fixed dimension, one can write algorithms that index
arrays as <code class="highlighter-rouge">A[i,j,k,...]</code> (good examples can be found in our linear
algebra code, where everything is a vector or matrix).  For algorithms
that have to support arbitrary dimensionality, for a long time our
fallback was linear indexing, <code class="highlighter-rouge">A[i]</code> for integer <code class="highlighter-rouge">i</code>. However, in
general SubArrays cannot be efficiently accessed by a linear index
because it results in call(s) to <code class="highlighter-rouge">div</code>, and <code class="highlighter-rouge">div</code> is slow. This is a
CPU problem, not a Julia-specific problem. The slowness of <code class="highlighter-rouge">div</code> is
still true despite the <a href="https://github.com/JuliaLang/julia/pull/15357">recent addition of
infrastructure</a> to make
it much faster—now one can make it merely “really bad” rather than
<a href="https://en.wikipedia.org/wiki/Alexander_and_the_Terrible,_Horrible,_No_Good,_Very_Bad_Day">“Terrible, Horrible, No Good, and Very
Bad”</a>.</p>

<p>The way we (largely) resolved this problem was to make it possible to
do cartesian indexing, <code class="highlighter-rouge">A[i,j,k,...]</code>, for arrays of arbitrary
dimensionality (the <code class="highlighter-rouge">CartesianIndex</code> type).  To leverage this in
practical code, we also had to extend our iterators with the <code class="highlighter-rouge">for I in
eachindex(A)</code> construct.  This allows one to select an iterator that
optimizes the efficiency of access to elements of <code class="highlighter-rouge">A</code>.  In generic
algorithms, the performance gains were not small, sometimes on the
scale of ten- to fifty-fold.  These types were described in a
<a href="http://julialang.org/blog/2016/02/iteration">previous blog post</a>.</p>

<p>To my knowledge, this approach has given Julia one of the most
flexible yet efficient “array view” types in any programming language.
Many languages base views on array <em>strides</em>, meaning situations in
which the memory offset is regular along each dimension.  Among other
things, this requires that the underlying array is dense.  In
contrast, in Julia we can easily handle non-strided arrays (e.g.,
sampling at <code class="highlighter-rouge">[1,3,17,428,...]</code> along one dimension, or creating a view
of a <code class="highlighter-rouge">SparseMatrixCSC</code>).  We can also handle arrays for which there is
no underlying storage (e.g., <code class="highlighter-rouge">Range</code>s).  Being able to do this with a
common infrastructure is part of what makes different optimized array
types useful in generic programming.</p>

<p>It’s also worth pointing out some problems:</p>

<ul>
  <li>
    <p>Most importantly, it requires that one adopt a slightly different
programming style. Despite being well into another release cycle,
this transition is still <a href="https://github.com/JuliaLang/julia/pull/15434#issuecomment-194991739">not complete, even in Base</a>.</p>
  </li>
  <li>
    <p>For algorithms that involve two or more arrays, there’s a
possibility that their “best” iterators will be of different
types. <em>In principle</em>, this is a big problem. Consider matrix-vector
multiplication, <code class="highlighter-rouge">A[i,j]*v[j]</code>, where <code class="highlighter-rouge">j</code> needs to be in-sync for
both <code class="highlighter-rouge">A</code> and <code class="highlighter-rouge">v</code>, yet you’d also like all of these accesses to be
maximally-efficient.  <em>In practice</em>, right now this isn’t a burning
problem: even if our arrays don’t all have efficient linear
indexing, to my knowledge all of our (dense) array types have
efficient cartesian indexing. Since indexing by <code class="highlighter-rouge">N</code> integers (where
<code class="highlighter-rouge">N</code> is equal to the dimensionality of the array) is always
performant, this serves as a reliable default for generic code.
(It’s worth noting that this isn’t true for sparse arrays, and the
lack of a corresponding generic solution is probably the main reason
we lack a generic API for writing sparse algorithms.)</p>
  </li>
</ul>

<p>Unfortunately, I suspect that if we want to add support for certain
new operations or types (specific examples below), it will force us to
set the latter problem on fire.</p>

<h1 id="challenging-examples">Challenging examples</h1>

<p>Some possible new <code class="highlighter-rouge">AbstractArray</code> types pose novel challenges.</p>

<h2 id="reshapedarrays-15449">ReshapedArrays (<a href="https://github.com/JuliaLang/julia/pull/15449">#15449</a>)</h2>

<p>These are the front-and-center motivation for this post. These are
motivated by a desire to ensure that <code class="highlighter-rouge">reshape(A, dims)</code> always returns
a “view” of <code class="highlighter-rouge">A</code> rather than allocating a copy of <code class="highlighter-rouge">A</code>. (Much of the
urgency of this julep goes away if we decide to abandon this goal, in
which case for consistency we should always return a copy of <code class="highlighter-rouge">A</code>.)
It’s worth noting that besides an explicit <code class="highlighter-rouge">reshape</code>, we have some
mechanisms for reshaping that currently cause a copy to be created,
notably <code class="highlighter-rouge">A[:]</code> or <code class="highlighter-rouge">A[:, :]</code> applied to a 3D array.</p>

<p>Similar to <code class="highlighter-rouge">SubArrays</code>, the main challenge for <code class="highlighter-rouge">ReshapedArrays</code> is
getting good performance.  If <code class="highlighter-rouge">A</code> is a 3D array, and you reshape it to
a 2D array <code class="highlighter-rouge">B</code>, then <code class="highlighter-rouge">B[i,j]</code> must be expanded to <code class="highlighter-rouge">A[k,l,m]</code>.  The
problem is that computing the correct <code class="highlighter-rouge">k,l,m</code> might result in a call
to <code class="highlighter-rouge">div</code>. So ReshapedArrays violate a crutch of our current ecosystem,
in that indexing with <code class="highlighter-rouge">N</code> integers might not be the fastest way to
access elements of <code class="highlighter-rouge">B</code>. From a performance perspective, this problem
is substantial (see <a href="https://github.com/JuliaLang/julia/pull/15449">#15449</a>, about five- to ten-fold).</p>

<p>In simple cases, there’s an easy way to circumvent this performance
problem: define a new iterator type that (internally) iterates over
the parent <code class="highlighter-rouge">A</code>’s indexes directly.  In other words, create an iterator
so that <code class="highlighter-rouge">B[I]</code> immediately expands to <code class="highlighter-rouge">A[I']</code>, and so that the latter
has “ideal” performance.</p>

<p>Unfortunately, this strategy runs into a lot of trouble when you need
to keep two arrays in sync: if you want to adopt this strategy, you
simply can’t write <code class="highlighter-rouge">B[i,j]*v[j]</code> for matrix-vector multiplication
anymore.  A potential way around <em>this</em> problem is to define a new class
of iterators that operate on specific dimensions of an array (<a href="https://github.com/JuliaLang/julia/pull/15459">#15459</a>),
writing <code class="highlighter-rouge">B[ii,jj]*v[j]</code>.  <code class="highlighter-rouge">jj</code> (whatever that is) and <code class="highlighter-rouge">j</code> need to be
in-sync, but they don’t necessarily need to both be integers. Using
this kind of strategy, matrix-vector multiplication</p>

<div class="language-jl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">1</span><span class="x">:</span><span class="n">size</span><span class="x">(</span><span class="n">B</span><span class="x">,</span> <span class="mi">2</span><span class="x">)</span>
    <span class="n">vj</span> <span class="o">=</span> <span class="n">v</span><span class="x">[</span><span class="n">j</span><span class="x">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="x">:</span><span class="n">size</span><span class="x">(</span><span class="n">B</span><span class="x">,</span> <span class="mi">1</span><span class="x">)</span>
        <span class="n">dest</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">+=</span> <span class="n">B</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="n">j</span><span class="x">]</span> <span class="o">*</span> <span class="n">vj</span>
    <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<p>might be written in a more performant manner like this:</p>

<div class="language-jl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="x">(</span><span class="n">jj</span><span class="x">,</span> <span class="n">vj</span><span class="x">)</span> <span class="k">in</span> <span class="n">zip</span><span class="x">(</span><span class="n">eachindex</span><span class="x">(</span><span class="n">B</span><span class="x">,</span> <span class="n">Dimension</span><span class="x">{</span><span class="mi">2</span><span class="x">}),</span> <span class="n">v</span><span class="x">)</span>
    <span class="k">for</span> <span class="x">(</span><span class="n">i</span><span class="x">,</span> <span class="n">ii</span><span class="x">)</span> <span class="k">in</span> <span class="n">zip</span><span class="x">(</span><span class="n">eachindex</span><span class="x">(</span><span class="n">dest</span><span class="x">),</span> <span class="n">eachindex</span><span class="x">(</span><span class="n">B</span><span class="x">,</span> <span class="x">(:,</span> <span class="n">jj</span><span class="x">)))</span>
        <span class="n">dest</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">+=</span> <span class="n">B</span><span class="x">[</span><span class="n">ii</span><span class="x">,</span><span class="n">jj</span><span class="x">]</span><span class="o">*</span><span class="n">vj</span>
    <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<p>It’s not too hard to figure out what <code class="highlighter-rouge">eachindex(B, Dimension{2})</code> and
<code class="highlighter-rouge">eachindex(B, (:, jj))</code> should do: <code class="highlighter-rouge">ii</code>, for example, could be a
<code class="highlighter-rouge">CartesianInnerIndex</code> (a type that does not yet exist) that for a
particular column of <code class="highlighter-rouge">B</code> iterates from <code class="highlighter-rouge">A[3,7,4]</code> to <code class="highlighter-rouge">A[5,8,4]</code>, where
the <code class="highlighter-rouge">d</code>th index component wraps around at <code class="highlighter-rouge">size(A, d)</code>.  The
big performance advantage of this strategy is that you only have to
compute a <code class="highlighter-rouge">div</code> to set the bounds of the iterator on each column; the
inner loop doesn’t require a <code class="highlighter-rouge">div</code> on each element access. No doubt,
given suitable definition of <code class="highlighter-rouge">jj</code> one could be even more clever and
avoid calculating <code class="highlighter-rouge">div</code> altogether.  To the author, this strategy
seems promising as a way to resolve the majority of the performance
concerns about ReshapedArrays—only if you needed “random access”
would you require slow (integer-based) operations.</p>

<p>However, a big problem is that compared to the “naive” implementation,
this is rather ugly.</p>

<h2 id="row-major-matrices-permuteddimensionarrays-and-taking-transposes-seriously">Row-major matrices, PermutedDimensionArrays, and “taking transposes seriously”</h2>

<p>Julia’s <code class="highlighter-rouge">Array</code> type stores its entries in column-major order, meaning
that <code class="highlighter-rouge">A[i,j]</code> and <code class="highlighter-rouge">A[i+1,j]</code> are in adjacent memory locations.  For
certain applications—or for interfacing with certain external code
bases—it might be convenient to support row-major arrays, where
instead <code class="highlighter-rouge">A[i,j]</code> and <code class="highlighter-rouge">A[i,j+1]</code> are in adjacent memory locations. More
fundamentally, this is partially related to one of the most
commented-on issues in all of julia’s development history, known as
“taking transposes seriously” aka <a href="https://github.com/JuliaLang/julia/issues/4774">#4774</a>.  There have been at least two
attempts at implementation, <a href="https://github.com/JuliaLang/julia/pull/6837">#6837</a> and the <code class="highlighter-rouge">mb/transpose</code> branch, and
for the latter a summary of benefits and challenges was <a href="https://github.com/JuliaLang/julia/issues/4774#issuecomment-149349751">posted</a>.</p>

<p>One of the biggest challenges mentioned was the huge explosion of
methods that one would need to support.  Can generic code come to the
rescue here?  There are two related concerns.  The first is linear
indexing: oftentimes this is conflated with “storage order,” i.e.,
given two linear indexes <code class="highlighter-rouge">i</code> and <code class="highlighter-rouge">j</code> for the same array, the offset in
memory is proportional to <code class="highlighter-rouge">i-j</code>.  For row-major arrays, this
notion is not viable, because otherwise a loop</p>

<div class="language-jl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> copy</span><span class="o">!</span><span class="x">(</span><span class="n">dest</span><span class="x">,</span> <span class="n">src</span><span class="x">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="x">:</span><span class="n">length</span><span class="x">(</span><span class="n">src</span><span class="x">)</span>
        <span class="n">dest</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">=</span> <span class="n">src</span><span class="x">[</span><span class="n">i</span><span class="x">]</span>  <span class="c"># trouble if `i` means "memory offset"</span>
    <span class="k">end</span>
    <span class="n">dest</span>
<span class="k">end</span>
</code></pre></div></div>

<p>would end up taking a transpose if <code class="highlighter-rouge">src</code> and <code class="highlighter-rouge">dest</code> don’t use the same
storage order.  Consequently, a linear index has to be defined in
terms of the corresponding cartesian (full-dimensionality) index.
This isn’t much of a real problem, because it’s one we know how to
solve: use <code class="highlighter-rouge">ind2sub</code> (which is slow) when you have to, but for
efficiency make row major arrays belong to the category (<code class="highlighter-rouge">LinearSlow</code>)
of arrays that defaults to iteration with cartesian indexes.  Doing so
will ensure that if one uses generic constructs like <code class="highlighter-rouge">eachindex(src)</code>
rather than <code class="highlighter-rouge">1:length(src)</code>, then the loop above can be fast.</p>

<p>The far more challenging problem concerns cache-efficiency: it’s much
slower to access elements of an array in anything other than
<a href="http://julialang.org/blog/2013/09/fast-numeric">storage-order</a>.  Some
reasonably fast ways to write matrix-vector multiplication are</p>

<div class="language-jl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">1</span><span class="x">:</span><span class="n">size</span><span class="x">(</span><span class="n">B</span><span class="x">,</span> <span class="mi">2</span><span class="x">)</span>
    <span class="n">vj</span> <span class="o">=</span> <span class="n">v</span><span class="x">[</span><span class="n">j</span><span class="x">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="x">:</span><span class="n">size</span><span class="x">(</span><span class="n">B</span><span class="x">,</span> <span class="mi">1</span><span class="x">)</span>
        <span class="n">dest</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">+=</span> <span class="n">B</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="n">j</span><span class="x">]</span> <span class="o">*</span> <span class="n">vj</span>
    <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>
<p>for a column-major matrix <code class="highlighter-rouge">B</code>, and</p>

<div class="language-jl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="x">:</span><span class="n">size</span><span class="x">(</span><span class="n">B</span><span class="x">,</span> <span class="mi">1</span><span class="x">)</span>
    <span class="k">for</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">1</span><span class="x">:</span><span class="n">size</span><span class="x">(</span><span class="n">B</span><span class="x">,</span> <span class="mi">2</span><span class="x">)</span>
        <span class="n">dest</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">+=</span> <span class="n">B</span><span class="x">[</span><span class="n">i</span><span class="x">,</span><span class="n">j</span><span class="x">]</span> <span class="o">*</span> <span class="n">v</span><span class="x">[</span><span class="n">j</span><span class="x">]</span>
    <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<p>for a row-major matrix.  (One can do even better than this by using a
scalar temporary accumulator, but let’s not worry about that here.)
The key point to note is that the order of the loops has been
switched.</p>

<p>One could generalize this by defining a <code class="highlighter-rouge">RowMajorRange</code> iterator
that’s a lot like our <code class="highlighter-rouge">CartesianRange</code> iterator, but traverses the
array in row-major order.  <code class="highlighter-rouge">eachindex</code> claims to return an “efficient
iterator,” and without a doubt the <code class="highlighter-rouge">RowMajorRange</code> is a (much) more
efficient iterator than a <code class="highlighter-rouge">CartesianRange</code> iterator for row-major
arrays. So let’s imagine that <code class="highlighter-rouge">eachindex</code> does what it says, and
returns a <code class="highlighter-rouge">RowMajorRange</code> iterator.  Using this strategy, the two
algorithms above can be combined into a single generic implementation:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for I in eachindex(B)
    dest[I[1]] += B[I]*v[I[2]]
end
</code></pre></div></div>

<p>Yay! Score one for efficient generic implementations.</p>

<p>But our triumph is short-lived. Let’s return to the example of
<code class="highlighter-rouge">copy!</code> above, and realize that <code class="highlighter-rouge">dest</code> and <code class="highlighter-rouge">src</code> might be two
different array types, and therefore might be most-efficiently indexed
with different iterator types.  We’re tempted to write this as</p>

<div class="language-jl highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> copy</span><span class="o">!</span><span class="x">(</span><span class="n">dest</span><span class="x">,</span> <span class="n">src</span><span class="x">)</span>
    <span class="k">for</span> <span class="x">(</span><span class="n">idest</span><span class="x">,</span> <span class="n">isrc</span><span class="x">)</span> <span class="k">in</span> <span class="n">zip</span><span class="x">(</span><span class="n">eachindex</span><span class="x">(</span><span class="n">dest</span><span class="x">),</span> <span class="n">eachindex</span><span class="x">(</span><span class="n">src</span><span class="x">))</span>
        <span class="n">dest</span><span class="x">[</span><span class="n">idest</span><span class="x">]</span> <span class="o">=</span> <span class="n">src</span><span class="x">[</span><span class="n">isrc</span><span class="x">]</span>
    <span class="k">end</span>
    <span class="n">dest</span>
<span class="k">end</span>
</code></pre></div></div>

<p>Up until we introduced our <code class="highlighter-rouge">RowMajorRange</code> return-type for
<code class="highlighter-rouge">eachindex</code>, this implementation would have been fine.  But we just
broke it, because now this will incorrectly take a transpose in
certain situations.</p>

<p>In other words, without careful design the goals of
“maximally-efficient iteration” and “keeping accesses in-sync” are in
conflict.</p>

<h2 id="offsetarrays-and-the-meaning-of-abstractarray">OffsetArrays and the meaning of AbstractArray</h2>

<p>Julia’s arrays are indexed starting at 1, whereas some other languages
start numbering at 0. If you take comments on various blog posts at
face value, there are vast armies of programmers out there eagerly
poised to adopt julia, but who won’t even try it because of this
difference in indexing.  Since recruiting those armies will lead to
world domination, this is clearly a problem of the utmost urgency.</p>

<p>More seriously, there <em>are</em> algorithms which simplify if you can index
outside of the range from <code class="highlighter-rouge">1:size(A,d)</code>.  In my own lab’s internal
code, we’ve long been using a <code class="highlighter-rouge">CenterIndexedArray</code> type, in which such
arrays (all of which have odd sizes) are indexed over the range <code class="highlighter-rouge">-n:n</code>
and for which 0 refers to the “center” element. One package which
generalizes this notion is <code class="highlighter-rouge">OffsetArrays</code>.  Unfortunately, in practice
both of these array types produce segfaults (due to built-in
assumptions about when <code class="highlighter-rouge">@inbounds</code> is appropriate) for many of julia’s
core functions; over time my lab has had to write implementations
specialized for <code class="highlighter-rouge">CenterIndexedArrays</code> for quite a few julia functions.</p>

<p><code class="highlighter-rouge">OffsetArrays</code> illustrates another conceptual challenge, which can
easily be demonstrated by <code class="highlighter-rouge">copy!</code>.  When <code class="highlighter-rouge">dest</code> is a 1-dimensional
<code class="highlighter-rouge">OffsetArray</code> and <code class="highlighter-rouge">src</code> is a standard <code class="highlighter-rouge">Vector</code>, what should <code class="highlighter-rouge">copy!</code>
do? In particular, where does <code class="highlighter-rouge">src[1]</code> go? Does it go in the <code class="highlighter-rouge">first</code>
element of <code class="highlighter-rouge">dest</code>, or does it get stored in <code class="highlighter-rouge">dest[1]</code> (which may not
be the first element).</p>

<p>Such examples force us to think a little more deeply about what an
array really is.  There seem to be two potential conceptions.  One is
that arrays are lists, and multidimensional arrays are
lists-of-lists-of-lists-of…  In such a world view, the right thing
to do is to put <code class="highlighter-rouge">src[1]</code> into the first slot of <code class="highlighter-rouge">dest</code>, because 1 is
just a synonym for <code class="highlighter-rouge">first</code>.  However, this world view doesn’t really
endow any kind of “meaning” to the index-tuple of an array, and in
that sense doesn’t even include the distinction conveyed by an
<code class="highlighter-rouge">OffsetArray</code>. In other words, in this world an <code class="highlighter-rouge">OffsetArray</code> is
simply nonsensical, and shouldn’t exist.</p>

<p>If instead one thinks <code class="highlighter-rouge">OffsetArray</code>s should exist, this essentially
forces one to adopt a different world view: arrays are effectively
associative containers, where each index-tuple is the “key” by which
one retrieves a value.  With this mode of thinking, <code class="highlighter-rouge">src[1]</code> should be
stored in <code class="highlighter-rouge">dest[1]</code>.</p>

<h1 id="formalizing-abstractarray">Formalizing AbstractArray</h1>

<p>These examples suggest a formalization of <code class="highlighter-rouge">AbstractArray</code>:</p>

<ul>
  <li>
    <p><code class="highlighter-rouge">AbstractArray</code>s are specialized associative containers, in that the
allowable “keys” may be restricted by more than just their julia
type.  Specifically, the allowable keys must be representable as a
cartesian product of one-dimensional lists of values.  The allowed
keys may depend not just on the array type but also the specific
array (e.g., its size).  Attempted access by keys that cannot be
converted to one of the allowed keys, for that specific array,
result in <code class="highlighter-rouge">BoundsError</code>s.</p>
  </li>
  <li>
    <p>For any given array, one must be able to generate a
finite-dimensional parametrization of the full domain of valid keys
from the array itself.  This might only require knowledge of the
array size, or the keys might depend on some internal storage (think
<code class="highlighter-rouge">DataFrames</code> and <code class="highlighter-rouge">OffsetArrays</code>).  In some cases, just the array
type might be sufficient (e.g., <code class="highlighter-rouge">FixedSizeArrays</code>).  By this
definition, note that a <code class="highlighter-rouge">Dict{ASCII5,Int}</code>, where <code class="highlighter-rouge">ASCII5</code> is a type
that means an ASCII string with 5 characters, would qualify as a
5-dimensional (sparse) array, but that a <code class="highlighter-rouge">Dict{ASCIIString,Int}</code>
would not (because there is no length limit to an <code class="highlighter-rouge">ASCIIString</code>, and
hence no finite dimensionality).</p>
  </li>
  <li>
    <p>An array may be indexed by more than one key type (i.e., keys may
have multiple parametrizations).  Different key parametrizations are
equivalent when they refer to the same element of a given
array. Linear indexes and cartesian indexes are simple examples of
interconvertable representations, but specialized iterators can
produce other key types as well.</p>
  </li>
  <li>
    <p>Arrays may support multiple iterators that produce non-equivalent
key sequences.  In other words, a row-major matrix may support both
<code class="highlighter-rouge">CartesianRange</code> and <code class="highlighter-rouge">RowMajorRange</code> iterators that access elements
in different orders.</p>
  </li>
</ul>

<h1 id="finding-a-way-forward">Finding a way forward</h1>

<p>Resolving these conflicting demands is not easy. One approach might be
to decree that some of these array types simply can’t be supported
with generic code. It is possible that this is the right
strategy. Alternatively, one can attept to devise an array API that
handles all of these types (and hopefully more).</p>

<p>In GitHub issue
<a href="https://github.com/JuliaLang/julia/issues/15648">#15648</a>, we are
discussing APIs that may resolve these challenges. Readers are
encouraged to contribute to this discussion.</p>


</div>



</div>
</div>
</div>

<br />


  </div>

  <footer class="container-fluid footer-copy">
  <div class="container">
    <div class="row">
      <div class="col-md-10 py-2">
        <p>
           ©2018 JuliaCN Julia 中文社区. All rights reserved.
        </p>
      </div>
    </div>
  </div>
</footer>

  <script src="/v2/js/jquery.min.js"></script>
<script src="/v2/js/bootstrap.min.js"></script>
<script src="/v2/js/platform.js"></script>
<script src="/v2/js/app.js"></script>
<script src="/v2/js/highlight.pack.js"></script>
<script async defer src="https://buttons.github.io/buttons.js"></script>
</body>

</html>
