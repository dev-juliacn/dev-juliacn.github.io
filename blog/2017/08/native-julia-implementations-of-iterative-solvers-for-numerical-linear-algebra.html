<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
<meta http-equiv="x-ua-compatible" content="ie=edge">
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title>GSoC 2017: Implementing iterative solvers for numerical linear algebra</title>
<meta name="author" content="Jeff Bezanson, Stefan Karpinski, Viral Shah, Alan Edelman, et al." />
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link href="https://fonts.googleapis.com/css?family=Roboto:400,400i,500,500i,700,700i" rel="stylesheet">
<link rel="stylesheet" href="/v2/css/bootstrap.min.css" />
<link rel="stylesheet" href="/v2/css/app.css" />
<link rel="stylesheet" href="/v2/css/fonts.css" />
<link rel="stylesheet" href="/v2/css/highlight/github.css" />
</head>

<body>

   

<!-- main menu -->
<div class="container py-3 py-lg-0">
  <nav class="navbar navbar-expand-lg navbar-light bg-light" id="main-menu">

    <a class="navbar-brand" href="/" id="logo">
      <img src="/v2/img/logo.png" height="55" width="118" />
    </a>

    <button class="navbar-toggler ml-auto hidden-sm-up float-xs-left" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <!-- li class="nav-item  flex-md-fill text-md-center">
          <a class="nav-link" href="/">Home</a>
        </li -->
        <li class="nav-item  flex-md-fill text-md-center">
          <a class="nav-link" href="/downloads">下载</a>
        </li>
        <li class="nav-item flex-md-fill text-md-center">
          <a class="nav-link" href="http://docs.juliacn.com/">文档</a>
        </li>
        <li class="nav-item  active  flex-md-fill text-md-center">
          <a class="nav-link" href="/blog/">Blog</a>
        </li>
        <li class="nav-item  flex-md-fill text-md-center">
          <a class="nav-link" href="/meetups">活动</a>
        </li>
      </ul>
    </div>

  </nav>
</div>
<!-- end main menu -->


   <br /><br />

  <div class="container">
    <br /><br />

<div class="container">

  <div class="row">
    <div class="col-12 col-lg-8 offset-lg-2">
      <h1></h1>

<div id="blogpost">
  <h1>GSoC 2017: Implementing iterative solvers for numerical linear algebra</h1>

  <p class="metadata">
    <span class="timestamp">23 Aug 2017</span>
    
    &nbsp;|&nbsp;
    <span class="author">Harmen Stoppels, Andreas Noack</span>
    
  </p>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
inlineMath: [ ['$','$'], ["\\(","\\)"] ],
displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
processEscapes: true,
processEnvironments: true
},
// Center justify equations in code and markdown cells. Elsewhere
// we use CSS to left justify single line equations in code cells.
displayAlign: 'center',
"HTML-CSS": {
styles: {'.MathJax_Display': {"margin": 0}},
linebreaks: { automatic: true }
}
});
</script>

<p>The central part of my GSoC project is about implementing the Jacobi-Davidson method natively in Julia, available in <a href="https://github.com/haampie/JacobiDavidson.jl">JacobiDavidson.jl</a>. This method computes a few approximate solutions of the eigenvalue problem $Ax = \lambda Bx$ for large and sparse matrices $A$ and $B$. As it uses iterative solvers internally, much time has gone into improving <a href="https://github.com/JuliaMath/IterativeSolvers.jl">IterativeSolvers.jl</a> in general. Lastly, as iterative solvers are typically used with preconditioners, I have implemented the incomplete LU factorization for sparse matrices as well in <a href="https://github.com/haampie/ILU.jl">ILU.jl</a>.</p>

<h2 id="jacobidavidsonjl">JacobiDavidson.jl</h2>
<p>The <a href="https://github.com/haampie/JacobiDavidson.jl">Jacobi-Davidson implementation</a> is ready for use and can be applied to solving the (generalized) eigenvalue problem for non-Hermitian matrices. It’s similar to the <code class="highlighter-rouge">eigs</code> method already available in Julia: it gives you a couple eigenvalues near a specified target in the complex plane.</p>

<p>At this point no official release has been tagged yet, as there is still some work to be done: hopefully the functions for the generalized and ordinary eigenvalue problem can largely be merged as they are very similar. Also, some optimizations for Hermitian problems should yet be implemented; lastly the methods do not yet support generic vectors and numbers.</p>

<h2 id="iterativesolversjl">IterativeSolvers.jl</h2>
<p>We have been preparing a new release of <a href="https://github.com/JuliaMath/IterativeSolvers.jl">IterativeSolvers.jl</a> that improves speed and memory usage of solvers like GMRES, CG, Chebyshev iteration, stationary methods and the Power Method. Also two new methods MINRES and BiCGStab(l) are available, together with efficient implementations of stationary methods for Julia’s <code class="highlighter-rouge">SparseMatrixCSC</code> matrix type.</p>

<p>Additionally the package has been upgraded to Julia 0.6 and the documentation has been restructured and improved.</p>

<h2 id="ilujl">ILU.jl</h2>
<p>Iterative methods for linear systems $Ax = b$ such as BiCGStab(l) might not converge quickly on any given matrix $A$. Typically convergence is best if the matrix $A$ is just a perturbation of the identity matrix. If that’s not the case, preconditioners might help: rather than solving $Ax = b$ you could try and solve $(PA)x = Pb$ where $P$ is a preconditioner such that $PA$ is closer to the identity matrix.</p>

<p>A perfect preconditioner would compute the full LU decomposition of $A$, but that’s too much computational work and would require way to much of memory. A well-known trick is to compute the LU factorization only approximately, by dropping small terms during the process. This is called incomplete LU or ILU.</p>

<p>As ILU for the <code class="highlighter-rouge">SparseMatrixCSC</code> type was not yet available in Julia, I’ve implemented it based on the article “Crout versions of ILU for general sparse matrices” by Na Li, Yousef Saad and Edmond Chow.</p>

<p>The package <a href="https://github.com/haampie/ILU.jl">ILU.jl</a> is completely ready for use and is well tested.</p>

<h2 id="examples">Examples</h2>
<p>Below you can find a few examples on how to use the packages I’ve been working on.</p>

<h3 id="jacobi-davidson">Jacobi-Davidson</h3>
<p>Let’s take a look at a toy example of the generalized eigenvalue problem $Ax = \lambda Bx$ where $A$ and $B$ are diagonal matrices of size $n \times n$ with $A_{kk} = \sqrt{k}$ and $B_{kk} = 1 / \sqrt{k}$. The eigenvalues are just the integers $1, \cdots, n$. Our goal is to find a few eigenvalues right in the interior of the spectrum near $n / 2$.</p>

<p>We implement the action of the matrices $A$ and $B$ matrix-free, using LinearMaps.jl:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">using</span> <span class="n">LinearMaps</span>

<span class="k">function</span><span class="nf"> myA</span><span class="o">!</span><span class="x">(</span><span class="n">y</span><span class="x">,</span> <span class="n">x</span><span class="x">)</span>
  <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span> <span class="x">:</span> <span class="n">length</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>
    <span class="nd">@inbounds</span> <span class="n">y</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">=</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">i</span><span class="x">)</span> <span class="o">*</span> <span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">]</span>
  <span class="k">end</span>
<span class="k">end</span>

<span class="k">function</span><span class="nf"> myB</span><span class="o">!</span><span class="x">(</span><span class="n">y</span><span class="x">,</span> <span class="n">x</span><span class="x">)</span>
  <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span> <span class="x">:</span> <span class="n">length</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>
    <span class="nd">@inbounds</span> <span class="n">y</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">=</span> <span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">/</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">i</span><span class="x">)</span>
  <span class="k">end</span>
<span class="k">end</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">100_000</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">LinearMap</span><span class="x">{</span><span class="kt">Complex128</span><span class="x">}(</span><span class="n">myA!</span><span class="x">,</span> <span class="n">n</span><span class="x">;</span> <span class="n">ismutating</span> <span class="o">=</span> <span class="n">true</span><span class="x">)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">LinearMap</span><span class="x">{</span><span class="kt">Complex128</span><span class="x">}(</span><span class="n">myB!</span><span class="x">,</span> <span class="n">n</span><span class="x">;</span> <span class="n">ismutating</span> <span class="o">=</span> <span class="n">true</span><span class="x">)</span>
</code></pre></div></div>

<p>The order of the matrices is <code class="highlighter-rouge">100_000</code>. It turns out that if we target eigenvalues in the interior of the spectrum, iterative solvers used internally in Jacobi-Davidson might have trouble solving very indefinite systems.</p>

<p>In that case we should use a preconditioner for $(A - \tau B)$, where $\tau$ is the target. We will just use the exact inverse, which is a diagonal matrix $P$ with entries $P_{kk} = \sqrt{k} / (k - \tau)$. It can be implemented matrix-free and in-place:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="n">Base</span><span class="o">.</span><span class="n">LinAlg</span><span class="o">.</span><span class="n">A_ldiv_B!</span>

<span class="n">struct</span> <span class="n">SuperPreconditioner</span><span class="x">{</span><span class="n">numT</span> <span class="o">&lt;:</span> <span class="n">Number</span><span class="x">}</span>
    <span class="n">target</span><span class="o">::</span><span class="n">numT</span>
<span class="k">end</span>

<span class="k">function</span><span class="nf"> A_ldiv_B</span><span class="o">!</span><span class="x">(</span><span class="n">p</span><span class="o">::</span><span class="n">SuperPreconditioner</span><span class="x">,</span> <span class="n">x</span><span class="x">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span> <span class="x">:</span> <span class="n">length</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>
        <span class="nd">@inbounds</span> <span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">*=</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">i</span><span class="x">)</span> <span class="o">/</span> <span class="x">(</span><span class="n">i</span> <span class="o">-</span> <span class="n">p</span><span class="o">.</span><span class="n">target</span><span class="x">)</span>
    <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<p>Now we call Jacobi-Davidson with the <code class="highlighter-rouge">Near</code> target and pass the preconditioner. We use GMRES as the iterative solver, but we could have used BiCGStabl(l) as well.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">using</span> <span class="n">JacobiDavidson</span>

<span class="n">τ</span> <span class="o">=</span> <span class="mf">50_000.1</span> <span class="o">+</span> <span class="mi">0</span><span class="nb">im</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">Near</span><span class="x">(</span><span class="n">τ</span><span class="x">)</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">SuperPreconditioner</span><span class="x">(</span><span class="n">τ</span><span class="x">)</span>

<span class="n">schur</span><span class="x">,</span> <span class="n">residuals</span> <span class="o">=</span> <span class="n">jdqz</span><span class="x">(</span><span class="n">A</span><span class="x">,</span> <span class="n">B</span><span class="x">,</span> 
    <span class="n">gmres_solver</span><span class="x">(</span><span class="n">n</span><span class="x">,</span> <span class="n">iterations</span> <span class="o">=</span> <span class="mi">10</span><span class="x">),</span>
    <span class="n">preconditioner</span> <span class="o">=</span> <span class="n">P</span><span class="x">,</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="x">,</span>
    <span class="n">pairs</span> <span class="o">=</span> <span class="mi">5</span><span class="x">,</span>
    <span class="n">ɛ</span> <span class="o">=</span> <span class="mf">1e-9</span><span class="x">,</span>
    <span class="n">min_dimension</span> <span class="o">=</span> <span class="mi">5</span><span class="x">,</span>
    <span class="n">max_dimension</span> <span class="o">=</span> <span class="mi">10</span><span class="x">,</span>
    <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">200</span><span class="x">,</span>
    <span class="n">verbose</span> <span class="o">=</span> <span class="n">true</span>
<span class="x">)</span>
</code></pre></div></div>

<p>It converges to the eigenvalues 49999, 50000, 50001, 50002 and 50004:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mf">50004.00000000014</span> <span class="o">+</span> <span class="mf">3.5749921718300463e-12</span><span class="nb">im</span>
<span class="mf">49999.999999986496</span> <span class="o">-</span> <span class="mf">7.348301591250897e-12</span><span class="nb">im</span>
<span class="mf">50001.00000000359</span> <span class="o">-</span> <span class="mf">1.9761169705101647e-11</span><span class="nb">im</span>
<span class="mf">49998.99999999998</span> <span class="o">-</span> <span class="mf">1.0866253642291695e-10</span><span class="nb">im</span>
<span class="mf">50002.00000000171</span> <span class="o">-</span> <span class="mf">2.3559720511618024e-11</span><span class="nb">im</span>
</code></pre></div></div>

<p>It does not yet detect 50003, but that might happen when <code class="highlighter-rouge">pairs</code> is increased a bit. As a result of our preconditioner, Jacobi-Davidson converges very quickly:</p>

<p><img src="/images/blog/2017-08-23-native-julia-implementations-of-iterative-solvers-for-numerical-linear-algebra/resnorm.svg" alt="Residual norm" /></p>

<p>It’s not easy to construct a preconditioner this good for any given problem, but usually people tend to know what works well in specific classes of problems. If no specific preconditioner is availabe, you can always try a general one such as ILU. The next section illustrates that.</p>

<h3 id="ilu-example">ILU example</h3>
<p>As an example of how ILU can be used we generate a non-symmetric, banded matrix having a structure that typically arises in finite differences schemes of three-dimensional problems:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">N</span> <span class="o">=</span> <span class="n">n</span><span class="o">^</span><span class="mi">3</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">spdiagm</span><span class="x">((</span><span class="n">fill</span><span class="x">(</span><span class="o">-</span><span class="mf">1.0</span><span class="x">,</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="x">),</span> <span class="n">fill</span><span class="x">(</span><span class="mf">3.0</span><span class="x">,</span> <span class="n">n</span><span class="x">),</span> <span class="n">fill</span><span class="x">(</span><span class="o">-</span><span class="mf">2.0</span><span class="x">,</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="x">)),</span> <span class="x">(</span><span class="o">-</span><span class="mi">1</span><span class="x">,</span> <span class="mi">0</span><span class="x">,</span> <span class="mi">1</span><span class="x">))</span>
<span class="n">Id</span> <span class="o">=</span> <span class="n">speye</span><span class="x">(</span><span class="n">n</span><span class="x">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">kron</span><span class="x">(</span><span class="n">A</span><span class="x">,</span> <span class="n">Id</span><span class="x">)</span> <span class="o">+</span> <span class="n">kron</span><span class="x">(</span><span class="n">Id</span><span class="x">,</span> <span class="n">A</span><span class="x">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">kron</span><span class="x">(</span><span class="n">A</span><span class="x">,</span> <span class="n">Id</span><span class="x">)</span> <span class="o">+</span> <span class="n">kron</span><span class="x">(</span><span class="n">Id</span><span class="x">,</span> <span class="n">A</span><span class="x">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">ones</span><span class="x">(</span><span class="n">N</span><span class="x">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">A</span> <span class="o">*</span> <span class="n">x</span>
</code></pre></div></div>

<p>The matrix $A$ has size $64^3 \times 64^3$. We want to solve the problem $Ax = b$ using for instance BiCGStab(2), but it turns out that convergence can get slow when the size of the problem grows. A quick benchmark shows it takes about 2.0 seconds to solve the problem to a reasonable tolerance:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> <span class="n">using</span> <span class="n">BenchmarkTools</span><span class="x">,</span> <span class="n">IterativeSolvers</span>
<span class="o">&gt;</span> <span class="n">my_x</span> <span class="o">=</span> <span class="nd">@btime</span> <span class="n">bicgstabl</span><span class="x">(</span><span class="o">$</span><span class="n">A</span><span class="x">,</span> <span class="o">$</span><span class="n">b</span><span class="x">,</span> <span class="mi">2</span><span class="x">,</span> <span class="n">max_mv_products</span> <span class="o">=</span> <span class="mi">2000</span><span class="x">);</span>
<span class="mf">2.051</span> <span class="n">s</span>
<span class="o">&gt;</span> <span class="n">norm</span><span class="x">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">A</span> <span class="o">*</span> <span class="n">my_x</span><span class="x">)</span> <span class="o">/</span> <span class="n">norm</span><span class="x">(</span><span class="n">b</span><span class="x">)</span>
<span class="mf">1.6967043606691152e-9</span>
</code></pre></div></div>

<p>Now let’s construct the ILU factorization:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> <span class="n">using</span> <span class="n">ILU</span>
<span class="o">&gt;</span> <span class="n">LU</span> <span class="o">=</span> <span class="n">crout_ilu</span><span class="x">(</span><span class="n">A</span><span class="x">,</span> <span class="n">τ</span> <span class="o">=</span> <span class="mf">0.1</span><span class="x">)</span>
<span class="o">&gt;</span> <span class="n">nnz</span><span class="x">(</span><span class="n">LU</span><span class="x">)</span> <span class="o">/</span> <span class="n">nnz</span><span class="x">(</span><span class="n">A</span><span class="x">)</span>
<span class="mf">2.1180353639352374</span>
</code></pre></div></div>

<p>Using the above drop tolerance $\tau$, our ILU factorization stores only about twice as many entries as the original matrix, which is reasonable. Let’s see what happens when we benchmark the solver again, now with ILU as a preconditioner:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> <span class="n">my_x</span> <span class="o">=</span> <span class="nd">@btime</span> <span class="n">bicgstabl</span><span class="x">(</span><span class="o">$</span><span class="n">A</span><span class="x">,</span> <span class="o">$</span><span class="n">b</span><span class="x">,</span> <span class="mi">2</span><span class="x">,</span> <span class="n">Pl</span> <span class="o">=</span> <span class="o">$</span><span class="n">LU</span><span class="x">,</span> <span class="n">max_mv_products</span> <span class="o">=</span> <span class="mi">2000</span><span class="x">);</span>
<span class="mf">692.187</span> <span class="n">ms</span>
<span class="o">&gt;</span> <span class="n">norm</span><span class="x">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">A</span> <span class="o">*</span> <span class="n">my_x</span><span class="x">)</span> <span class="o">/</span> <span class="n">norm</span><span class="x">(</span><span class="n">b</span><span class="x">)</span>
<span class="mf">2.133397068536056e-9</span>
</code></pre></div></div>

<p>It solves the problem 66% faster to the same tolerance. There is of course a caveat, as constructing the preconditioner itself takes time as well:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;</span> <span class="n">LU</span> <span class="o">=</span> <span class="nd">@btime</span> <span class="n">crout_ilu</span><span class="x">(</span><span class="o">$</span><span class="n">A</span><span class="x">,</span> <span class="n">τ</span> <span class="o">=</span> <span class="mf">0.1</span><span class="x">);</span>
<span class="mf">611.019</span> <span class="n">ms</span>
</code></pre></div></div>

<p>So all in all the problem is solved about 36% faster. However, if we have multiple right-hand sides for the same matrix, we can construct the preconditioner only once and use it multiple times. Even when the matrix changes slightly you could reuse the ILU factorization. The latter is exactly what happens in Jacobi-Davidson.</p>

<h2 id="acknowledgements">Acknowledgements</h2>

<p>I would really want to thank my GSoC mentor Andreas Noack for the many discussions we had in chat and video calls. Also I would like to thank the Julia community in general for giving me a warm welcome, both online and at JuliaCon 2017.</p>


</div>



</div>
</div>
</div>

<br />


  </div>

  <footer class="container-fluid footer-copy">
  <div class="container">
    <div class="row">
      <div class="col-md-10 py-2">
        <p>
           ©2018 JuliaCN Julia 中文社区. All rights reserved.
        </p>
      </div>
    </div>
  </div>
</footer>

  <script src="/v2/js/jquery.min.js"></script>
<script src="/v2/js/bootstrap.min.js"></script>
<script src="/v2/js/platform.js"></script>
<script src="/v2/js/app.js"></script>
<script src="/v2/js/highlight.pack.js"></script>
<script async defer src="https://buttons.github.io/buttons.js"></script>
</body>

</html>
