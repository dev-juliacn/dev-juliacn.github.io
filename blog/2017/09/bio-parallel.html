<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
<meta http-equiv="x-ua-compatible" content="ie=edge">
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title>GSoC 2017: Parallelism in BioJulia</title>
<meta name="author" content="Jeff Bezanson, Stefan Karpinski, Viral Shah, Alan Edelman, et al." />
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link href="https://fonts.googleapis.com/css?family=Roboto:400,400i,500,500i,700,700i" rel="stylesheet">
<link rel="stylesheet" href="/v2/css/bootstrap.min.css" />
<link rel="stylesheet" href="/v2/css/app.css" />
<link rel="stylesheet" href="/v2/css/fonts.css" />
<link rel="stylesheet" href="/v2/css/highlight/github.css" />
</head>

<body>

   

<!-- main menu -->
<div class="container py-3 py-lg-0">
  <nav class="navbar navbar-expand-lg navbar-light bg-light" id="main-menu">

    <a class="navbar-brand" href="/" id="logo">
      <img src="/v2/img/logo.png" height="55" width="118" />
    </a>

    <button class="navbar-toggler ml-auto hidden-sm-up float-xs-left" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <!-- li class="nav-item  flex-md-fill text-md-center">
          <a class="nav-link" href="/">Home</a>
        </li -->
        <li class="nav-item  flex-md-fill text-md-center">
          <a class="nav-link" href="/downloads">下载</a>
        </li>
        <li class="nav-item flex-md-fill text-md-center">
          <a class="nav-link" href="http://docs.juliacn.com/">文档</a>
        </li>
        <li class="nav-item  active  flex-md-fill text-md-center">
          <a class="nav-link" href="/blog/">Blog</a>
        </li>
        <li class="nav-item  flex-md-fill text-md-center">
          <a class="nav-link" href="/meetups">活动</a>
        </li>
      </ul>
    </div>

  </nav>
</div>
<!-- end main menu -->


   <br /><br />

  <div class="container">
    <br /><br />

<div class="container">

  <div class="row">
    <div class="col-12 col-lg-8 offset-lg-2">
      <h1></h1>

<div id="blogpost">
  <h1>GSoC 2017: Parallelism in BioJulia</h1>

  <p class="metadata">
    <span class="timestamp">07 Sep 2017</span>
    
    &nbsp;|&nbsp;
    <span class="author">Kenta Sato</span>
    
  </p>

  <p>In this summer, I have worked on a project to develop tools that make BioJulia
run faster. As an outcome, Automa.jl now generates more efficient code to parse
text files, ConcurrentCalls.jl runs multiple tasks in parallel, and simple and
efficient interfaces to various compression formats are provided in
TranscodingStreams.jl.</p>

<h2 id="instruction-level-parallelism">Instruction-level parallelism</h2>

<p>Instruction-level parallelism is a technique to run multiple instructions
simultaneously on a CPU core. This may sound odd but actually it is possible
because CPU instructions are executed in multiple stages such as fetch, decode,
execute, and so on. This is called <a href="https://en.wikipedia.org/wiki/Instruction_pipelining">instruction
pipelining</a> and modern
processors can execute these stages in parallel and hence processing throughput
may be boosted by utilizing it.</p>

<p>I implemented automatic loop unrolling in
<a href="https://github.com/BioJulia/Automa.jl">Automa.jl</a>, which is a package to
generate finite state machine (FSM) from regular expressions. We use it to
generate high-performance parsers for various file formats used in
bioinformatics.  The loop unrolling factor can be specified as an argument of
<a href="http://biojulia.net/Automa.jl/latest/references.html#Automa.CodeGenContext"><code class="highlighter-rouge">Automa.CodeGenContext</code></a>.
For example, you can specify the value 8 in this way: <code class="highlighter-rouge">context =
Automa.CodeGenContext(loopunroll=8)</code> and that is all. The code generator of
Automa.jl will automatically unroll loops found in an FSM.</p>

<p>Automa.jl works by incrementally increasing a reading position variable and
reading data byte by byte from a buffer. This is difficult to unroll because the
position variable creates a critical path of data dependencies. So, Automa.jl
unrolls particular nodes in an FSM that have a self edge and have no actions
within state transition.</p>

<p>Let’s see the improvement of performance.
<a href="https://en.wikipedia.org/wiki/FASTA_format">FASTA</a> and
<a href="https://en.wikipedia.org/wiki/FASTQ_format">FASTQ</a> are one of the most common
file formats to store biological sequences. I benchmarked parsing throughput in
these two formats. The throughput improved as the loop unrolling factor was
increased and saturated around factor = 10.
<img src="/images/blog/2017-09-07-bio-parallel/fasta-fastq-benchmarks.png" alt="FASTA-FASTQ benchmarks" /></p>

<p>Unrolled parsing achieved about 1.3 times speedup in both cases.  This benchmark
does not include I/O operations but other operations that are required to
convert byte data to our data type are included. The improvement may not look
surprising, however, we should note that it is achieved almost for free. There
is no need to use more CPU cores.</p>

<h2 id="task-level-parallelism">Task-level parallelism</h2>

<p><a href="https://github.com/bicycle1885/ConcurrentCalls.jl">ConcurrentCalls.jl</a> is a
package that makes function calls (or tasks) run concurrently. It exports a
macro <code class="highlighter-rouge">@cc</code> that transforms Julia code to code that calls functions on remote
processes.  This is a conceptual example of running tasks in parallel:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>addprocs(2)
using ConcurrentCalls

function multitask()
    # Define some time-consuming (say &gt;10ms) task(s).
    function sum(x, y)
        sleep(2)
        return x + y
    end
    function prod(x, y)
        sleep(1)
        return x * y
    end

    # Call functions concurrently using multiple processes.
    @cc begin
        x = sum(1, 2)       # =&gt;  3
        y = sum(3, 4)       # =&gt;  7
        prod(x, sum(y, 1))  # =&gt; 24
    end
end

multitask()  # =&gt; 24
</code></pre></div></div>

<p>In the example above, <code class="highlighter-rouge">x = sum(1, 2)</code> and <code class="highlighter-rouge">y = sum(3, 4)</code> will be executed in
parallel on different processes. These function calls are arranged by a
scheduler of ConcurrentCalls.jl and each taks is assigned to a worker process
based on some heuristics. The third line inside the <code class="highlighter-rouge">@cc</code> macro has two function
calls. Each of them will also be assigned to a worker but it never starts until
the first two finish. Dependencies of tasks are handled by the scheduler and a
task will not be executed until all of its arguments are finished and results
are available.</p>

<p>Execution of tasks are defined in an imperative way and so its semantics would
be apparent from the code. Data dependencies are naturally expressed by
arguments passed to functions.  The code below shows three examples that use a
for loop to describe a job:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># independent tasks
@cc begin
    for i in 1:100
        task()
    end
end

# sequential taks (not parallelizable)
@cc begin
    a = task1()
    for i in 1:100
        a = task2(a)
    end
end

# biparallel tasks
@cc begin
    a = task1()
    b = task2()
    for i in 1:100
        a = task3(a)
        b = task4(b)
    end
end
</code></pre></div></div>

<p>This package is still at a very early stage of development but some simple
subset of Julia code can be executed in parallel. See the
<a href="https://github.com/bicycle1885/ConcurrentCalls.jl#usage">README</a> page of
ConcurrentCalls.jl for more examples and some caveats.</p>

<h2 id="new-io-apis">New I/O APIs</h2>

<p>A difficulty of parallelizing data processing in bioinformatics is that input
files are often compressed. The most common compression format, gzip, does not
support either parallel decompression or splitting data into smaller chunks.
Some special file formats (<a href="https://github.com/BioJulia/BGZFStreams.jl">BGZF</a>
for example) can support parallel decompression and chunking but gzip is still
slow.</p>

<p>A recent compression algorithm known as
<a href="http://facebook.github.io/zstd/">Zstandard</a> (or Zstd) is much faster than gzip
while keeping the compression ratio at the same level of gzip. Moreover, it
started to implement an experimental support of <a href="https://github.com/facebook/zstd/blob/dev/contrib/seekable_format/zstd_seekable_compression_format.md">seekable compression
format</a>,
in which data are split into frames and each of which are compressed
independently. Tables to seek to a specific position are stored in <em>skippable</em>
frames and hence it can support parallel processing and chunking.</p>

<p>To support this feature, I implemented an interface package to Zstd, which is
already available as
<a href="https://github.com/bicycle1885/CodecZstd.jl">CodecZstd.jl</a>. While it does not
yet support the seekable format, we can enjoy the performance of Zstd
immediately. Also, this package is built on top of
<a href="https://github.com/bicycle1885/TranscodingStreams.jl">TranscodingStreams.jl</a>,
which offers simple and consistent APIs for many data formats. Currently, <a href="https://github.com/bicycle1885/CodecZlib.jl">gzip
(zlib)</a>,
<a href="https://github.com/bicycle1885/CodecBzip2.jl">bzip2</a>,
<a href="https://github.com/bicycle1885/CodecXz.jl">xz</a>, and
<a href="https://github.com/bicycle1885/CodecZstd.jl">zstd</a> are supported. These
packages are replacements of <a href="https://github.com/BioJulia/Libz.jl">Libz.jl</a> and
<a href="https://github.com/BioJulia/BufferedStreams.jl">BufferedStreams.jl</a> I maintain.</p>

<h2 id="plans">Plans</h2>

<p>Speeding up programs never ends. I still have some pending pull requests that
are required to work well with these tools
(<a href="https://github.com/BioJulia/BioCore.jl/pull/7">https://github.com/BioJulia/BioCore.jl/pull/7</a>,
<a href="https://github.com/BioJulia/BioAlignments.jl/pull/4">https://github.com/BioJulia/BioAlignments.jl/pull/4</a>,
<a href="https://github.com/BioJulia/BioSequences.jl/pull/25">https://github.com/BioJulia/BioSequences.jl/pull/25</a>). ConcurrentCalls.jl lacks
examples, tests, benchmarks, and many features to be used in real work.
CodecZstd.jl will support the seekable format once it gets stable. I really
welcome feedbacks of these designs and ideas to improve them further.</p>

<h2 id="acknowledgments">Acknowledgments</h2>

<p>I appreciate contributions of my mentor Shashi Gowda and other members of the
Julia community.</p>


</div>



</div>
</div>
</div>

<br />


  </div>

  <footer class="container-fluid footer-copy">
  <div class="container">
    <div class="row">
      <div class="col-md-10 py-2">
        <p>
           ©2018 JuliaCN Julia 中文社区. All rights reserved.
        </p>
      </div>
    </div>
  </div>
</footer>

  <script src="/v2/js/jquery.min.js"></script>
<script src="/v2/js/bootstrap.min.js"></script>
<script src="/v2/js/platform.js"></script>
<script src="/v2/js/app.js"></script>
<script src="/v2/js/highlight.pack.js"></script>
<script async defer src="https://buttons.github.io/buttons.js"></script>
</body>

</html>
